{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bf54c96",
   "metadata": {},
   "source": [
    "## Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54a38c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.data import Dataset as tfd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3bf1f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train_data.txt\",\n",
    "                       engine=\"python\",\n",
    "                       sep=\" ::: \",\n",
    "                       names=[\"id\", \"movie\", \"genre\", \"summary\"])\n",
    "\n",
    "test_df = pd.read_csv(\"test_data_solution.txt\",\n",
    "                      engine=\"python\",\n",
    "                      sep=\" ::: \",\n",
    "                      names=[\"id\", \"movie\", \"genre\", \"summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f42099",
   "metadata": {},
   "source": [
    "### Viewing a small portion of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "571c3641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>movie</th>\n",
       "      <th>genre</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Oscar et la dame rose (2009)</td>\n",
       "      <td>drama</td>\n",
       "      <td>Listening in to a conversation between his doc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Cupid (1997)</td>\n",
       "      <td>thriller</td>\n",
       "      <td>A brother and sister with a past incestuous re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Young, Wild and Wonderful (1980)</td>\n",
       "      <td>adult</td>\n",
       "      <td>As the bus empties the students for their fiel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>The Secret Sin (1915)</td>\n",
       "      <td>drama</td>\n",
       "      <td>To help their unemployed father make ends meet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>The Unrecovered (2007)</td>\n",
       "      <td>drama</td>\n",
       "      <td>The film's title refers not only to the un-rec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                             movie     genre  \\\n",
       "0   1      Oscar et la dame rose (2009)     drama   \n",
       "1   2                      Cupid (1997)  thriller   \n",
       "2   3  Young, Wild and Wonderful (1980)     adult   \n",
       "3   4             The Secret Sin (1915)     drama   \n",
       "4   5            The Unrecovered (2007)     drama   \n",
       "\n",
       "                                             summary  \n",
       "0  Listening in to a conversation between his doc...  \n",
       "1  A brother and sister with a past incestuous re...  \n",
       "2  As the bus empties the students for their fiel...  \n",
       "3  To help their unemployed father make ends meet...  \n",
       "4  The film's title refers not only to the un-rec...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40153512",
   "metadata": {},
   "source": [
    "## Cleaning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f74f0f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import PorterStemmer, SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def clean_review(review):\n",
    "    '''\n",
    "    Input:\n",
    "        review: a string containing a review.\n",
    "    Output:\n",
    "        review_cleaned: a processed review. \n",
    "    '''\n",
    "    review = review[0] if type(review) != str else review\n",
    "    if type(review) == np.ndarray:\n",
    "        print(review, review[0])\n",
    "        review = review[0]\n",
    "        \n",
    "    lower_string = review.lower()\n",
    "    no_url_str = re.sub(r'https?:\\/\\/\\.*','', lower_string)\n",
    "    clean_str = re.sub(r'[^a-zA-Z]', ' ', no_url_str)  # removing special characters, numbers, punctuations\n",
    "#     print(clean_str)\n",
    "    \n",
    "    stop_words_set = set(stopwords.words('english'))\n",
    "    stemmer_object = PorterStemmer()  # SnowballStemmer(language='english')\n",
    "#     lemma_obj = WordNetLemmatizer()\n",
    "  \n",
    "    review_str_tokens = word_tokenize(clean_str)\n",
    "    clean_word_list = [stemmer_object.stem(a_token) for a_token in review_str_tokens if not a_token.lower() in stop_words_set]\n",
    "    \n",
    "    clean_review = ' '.join(clean_word_list)\n",
    "    return clean_review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b0be02",
   "metadata": {},
   "source": [
    "### Shuffling and Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2706b810",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_shuffled = train_df.sample(frac=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_shuffled[\"summary\"],\n",
    "                                                 train_shuffled[\"genre\"],\n",
    "                                                 test_size=0.1)\n",
    "X_test, y_test = test_df[\"summary\"], test_df[\"genre\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e9706c",
   "metadata": {},
   "source": [
    "### One hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c92adf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse=False)\n",
    "ohe.fit(train_shuffled[\"genre\"].to_numpy().reshape(-1,1)) # Fit the encoder to genre of training data\n",
    "\n",
    "train_ohe = ohe.transform(y_train.to_numpy().reshape(-1, 1))\n",
    "val_ohe = ohe.transform(y_val.to_numpy().reshape(-1,1))\n",
    "test_ohe = ohe.transform(y_test.to_numpy().reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19e16169",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = X_train.tolist()\n",
    "val_sentences = X_val.tolist()\n",
    "test_sentences = X_test.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa64854",
   "metadata": {},
   "source": [
    "### Universal Serial Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3fb30473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 27), dtype=tf.float64, name=None))>,\n",
       " <PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 27), dtype=tf.float64, name=None))>,\n",
       " <PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 27), dtype=tf.float64, name=None))>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "                                        trainable=False,\n",
    "                                        name=\"universal_sentence_encoder\")\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset = tfd.from_tensor_slices((X_train, train_ohe)).batch(32).prefetch(AUTOTUNE)\n",
    "val_dataset = tfd.from_tensor_slices((X_val, val_ohe)).batch(32).prefetch(AUTOTUNE)\n",
    "test_dataset = tfd.from_tensor_slices((X_test, test_ohe)).batch(32).prefetch(AUTOTUNE)\n",
    "\n",
    "train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74ebe4c",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b129e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None,)]                 0         \n",
      "                                                                 \n",
      " universal_sentence_encoder   (None, 512)              256797824 \n",
      " (KerasLayer)                                                    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 27)                13851     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 257,074,331\n",
      "Trainable params: 276,507\n",
      "Non-trainable params: 256,797,824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classes = len(train_shuffled[\"genre\"].value_counts())\n",
    "\n",
    "# Build the model\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape=[], dtype=\"string\")\n",
    "x = embedding_layer(inputs)\n",
    "x = layers.Dense(512, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(classes, activation=\"softmax\")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d973c532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "152/152 [==============================] - 14s 64ms/step - loss: 2.0494 - accuracy: 0.4414 - val_loss: 1.6616 - val_accuracy: 0.5312\n",
      "Epoch 2/5\n",
      "152/152 [==============================] - 10s 63ms/step - loss: 1.5913 - accuracy: 0.5350 - val_loss: 1.4812 - val_accuracy: 0.5625\n",
      "Epoch 3/5\n",
      "152/152 [==============================] - 9s 59ms/step - loss: 1.4791 - accuracy: 0.5487 - val_loss: 1.4053 - val_accuracy: 0.5607\n",
      "Epoch 4/5\n",
      "152/152 [==============================] - 9s 59ms/step - loss: 1.4390 - accuracy: 0.5641 - val_loss: 1.3652 - val_accuracy: 0.5735\n",
      "Epoch 5/5\n",
      "152/152 [==============================] - 9s 61ms/step - loss: 1.3682 - accuracy: 0.5845 - val_loss: 1.3666 - val_accuracy: 0.5790\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset,\n",
    "                  steps_per_epoch=int(0.1*len(train_dataset)),\n",
    "                  epochs=5,\n",
    "                  validation_data=val_dataset,\n",
    "                  validation_steps=int(0.1*len(val_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6f06a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1694/1694 [==============================] - 87s 52ms/step - loss: 1.3716 - accuracy: 0.5773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3715871572494507, 0.5772877931594849]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc258f6",
   "metadata": {},
   "source": [
    "Conclusion:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
